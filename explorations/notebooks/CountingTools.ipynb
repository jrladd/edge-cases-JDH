{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Tools\n",
    "## How to Count Words in Python and Pandas\n",
    "\n",
    "This notebook gives a brief introduction to counting words in Python and Pandas. While word counting is the most basic form of text mining, it still involves a number of interpretative steps. To help you understand our choices in our article, we are providing this notebook as a supplementary resource and introduction to these tradeoffs. We are not attempting to be comprehensive here, but rather to give you a sense of the kinds of decisions that go into word counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For additional resources, see William J. Turkel and Adam Crymble, \"Counting Word Frequencies with Python,\" *Programming Historian* 1 (2012), https://doi.org/10.46430/phen0003 and Megan S. Kane, \"Corpus Analysis with spaCy,\" *Programming Historian* 12 (2023), https://doi.org/10.46430/phen0113."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Relevant Libraries and Create Shared Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zleblanc/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "## If you haven't downloaded the NLTK data sets yet, do so:\n",
    "def download_nltk_data_if_needed(packages):\n",
    "    for package in packages:\n",
    "        try:\n",
    "            nltk.data.find(package)\n",
    "        except LookupError:\n",
    "            nltk.download(package)\n",
    "\n",
    "download_nltk_data_if_needed(['tokenizers/punkt', 'corpora/stopwords', 'wordnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_cells(val):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: red'` for negative\n",
    "    strings, `'color: green'` for positive strings.\n",
    "    \"\"\"\n",
    "    color = 'red' if val > 0 else 'blue'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "def make_pretty(styler, subset_columns):\n",
    "    styler.applymap(color_cells, subset=subset_columns)\n",
    "    return styler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Example Dataset\n",
    "\n",
    "Given our article's focus on DH tools, we are creating a dataset that explores how we count the word `tool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digital tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Critical Tool Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Footstool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DH TOOLSETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tooling up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            example_text\n",
       "0          digital tools\n",
       "1  Critical Tool Studies\n",
       "2              Footstool\n",
       "3            DH TOOLSETS\n",
       "4             tooling up"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tool_data = pd.DataFrame({'example_text': ['digital tools', 'Critical Tool Studies', 'Footstool', 'DH TOOLSETS', 'tooling up']})\n",
    "example_tool_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counting Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: String Matching\n",
    "\n",
    "Computers are very good at counting things, but also very literal. The simplest way to count words is to tell the computer to look for the word you want to count. This is called \"string matching.\" In Pandas, we can do this with the `str.count()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f956d_row0_col1, #T_f956d_row2_col1, #T_f956d_row4_col1 {\n",
       "  color: red;\n",
       "}\n",
       "#T_f956d_row1_col1, #T_f956d_row3_col1 {\n",
       "  color: blue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f956d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f956d_level0_col0\" class=\"col_heading level0 col0\" >example_text</th>\n",
       "      <th id=\"T_f956d_level0_col1\" class=\"col_heading level0 col1\" >string_matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f956d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f956d_row0_col0\" class=\"data row0 col0\" >digital tools</td>\n",
       "      <td id=\"T_f956d_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f956d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f956d_row1_col0\" class=\"data row1 col0\" >Critical Tool Studies</td>\n",
       "      <td id=\"T_f956d_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f956d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f956d_row2_col0\" class=\"data row2 col0\" >Footstool</td>\n",
       "      <td id=\"T_f956d_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f956d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f956d_row3_col0\" class=\"data row3 col0\" >DH TOOLSETS</td>\n",
       "      <td id=\"T_f956d_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f956d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f956d_row4_col0\" class=\"data row4 col0\" >tooling up</td>\n",
       "      <td id=\"T_f956d_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1774876a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tool_data['string_matching'] = example_tool_data['example_text'].str.count('tool')\n",
    "example_tool_data.style.pipe(make_pretty, subset_columns=['string_matching']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this quick example, we can see that three of our examples are counted correctly, but two are not (`Critical tool Studies` and `DH TOOLSETS`). This is because the `str.count()` method is case sensitive, and those examples are capitalized and uppercase, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_02b9e_row0_col1, #T_02b9e_row1_col1, #T_02b9e_row2_col1, #T_02b9e_row3_col1, #T_02b9e_row4_col1 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_02b9e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_02b9e_level0_col0\" class=\"col_heading level0 col0\" >example_text</th>\n",
       "      <th id=\"T_02b9e_level0_col1\" class=\"col_heading level0 col1\" >string_matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_02b9e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_02b9e_row0_col0\" class=\"data row0 col0\" >digital tools</td>\n",
       "      <td id=\"T_02b9e_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02b9e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_02b9e_row1_col0\" class=\"data row1 col0\" >Critical Tool Studies</td>\n",
       "      <td id=\"T_02b9e_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02b9e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_02b9e_row2_col0\" class=\"data row2 col0\" >Footstool</td>\n",
       "      <td id=\"T_02b9e_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02b9e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_02b9e_row3_col0\" class=\"data row3 col0\" >DH TOOLSETS</td>\n",
       "      <td id=\"T_02b9e_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02b9e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_02b9e_row4_col0\" class=\"data row4 col0\" >tooling up</td>\n",
       "      <td id=\"T_02b9e_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1181e9580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tool_data['string_matching'] = example_tool_data['example_text'].str.count('tool|Tool|TOOL')\n",
    "example_tool_data.style.pipe(make_pretty, subset_columns=['string_matching']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used a simple `OR` pipe operator to count all the versions of tools, which has worked. But we are currently counting `Footstool` a word that contains `tool` but not an instance of `tool`. Consequently, straight string matching is slightly too permissive for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Tokenization\n",
    "\n",
    "Rather than counting strings, we can count words. This is called \"tokenization.\" Tokenization is the process of breaking up a string into smaller units, called tokens. In this case, we want to break up our string into words. We can do this with the `str.split()` method. Tokenization is very language-specific, but since our data is in English, we can use the default settings. For an example of non-English tokenization, see Melanie Walsh, *Introduction to Cultural Analytics & Python*, Version 1 (2021), https://doi.org/10.5281/zenodo.4411250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e532a_row0_col1, #T_e532a_row1_col1, #T_e532a_row1_col3, #T_e532a_row2_col1, #T_e532a_row3_col1, #T_e532a_row4_col1 {\n",
       "  color: red;\n",
       "}\n",
       "#T_e532a_row0_col3, #T_e532a_row2_col3, #T_e532a_row3_col3, #T_e532a_row4_col3 {\n",
       "  color: blue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e532a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e532a_level0_col0\" class=\"col_heading level0 col0\" >example_text</th>\n",
       "      <th id=\"T_e532a_level0_col1\" class=\"col_heading level0 col1\" >string_matching</th>\n",
       "      <th id=\"T_e532a_level0_col2\" class=\"col_heading level0 col2\" >tokenized_example_text</th>\n",
       "      <th id=\"T_e532a_level0_col3\" class=\"col_heading level0 col3\" >tokenized_string_matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e532a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e532a_row0_col0\" class=\"data row0 col0\" >digital tools</td>\n",
       "      <td id=\"T_e532a_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_e532a_row0_col2\" class=\"data row0 col2\" >['digital', 'tools']</td>\n",
       "      <td id=\"T_e532a_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e532a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e532a_row1_col0\" class=\"data row1 col0\" >Critical Tool Studies</td>\n",
       "      <td id=\"T_e532a_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_e532a_row1_col2\" class=\"data row1 col2\" >['Critical', 'Tool', 'Studies']</td>\n",
       "      <td id=\"T_e532a_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e532a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e532a_row2_col0\" class=\"data row2 col0\" >Footstool</td>\n",
       "      <td id=\"T_e532a_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_e532a_row2_col2\" class=\"data row2 col2\" >['Footstool']</td>\n",
       "      <td id=\"T_e532a_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e532a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e532a_row3_col0\" class=\"data row3 col0\" >DH TOOLSETS</td>\n",
       "      <td id=\"T_e532a_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "      <td id=\"T_e532a_row3_col2\" class=\"data row3 col2\" >['DH', 'TOOLSETS']</td>\n",
       "      <td id=\"T_e532a_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e532a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e532a_row4_col0\" class=\"data row4 col0\" >tooling up</td>\n",
       "      <td id=\"T_e532a_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "      <td id=\"T_e532a_row4_col2\" class=\"data row4 col2\" >['tooling', 'up']</td>\n",
       "      <td id=\"T_e532a_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1774bd1c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tool_data['tokenized_example_text'] = example_tool_data['example_text'].apply(word_tokenize)\n",
    "example_tool_data['tokenized_string_matching'] = example_tool_data['tokenized_example_text'].apply(lambda x: sum(1 for token in x if token in ['tool', 'Tool', 'TOOL']))\n",
    "example_tool_data.style.pipe(make_pretty, subset_columns=['string_matching', 'tokenized_string_matching']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have tokenized our `example_text` using the `NLTK` library, rather than `str.split(' ')` since we use NLTK in our article (but they are essentially the same here). We can see that in this example we are now only getting the exact match for `tool`, and not any of other examples. This approach is much more restrictive than string matching. We could add `tools` to our list of allowed terms to get `digital tools`, though then we would need to write `tools` and `Tools` and `TOOLS` to be equally comprehensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3: Lowercasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having to write out all versions of our terms, we can lowercase all of our text to help normalize our data. This will help us avoid the problem of case sensitivity. We can do this with the `str.lower()` method. This type of transformation is often part of pre-processing or data cleaning, but can be enormously impactful on the results of your analysis. However, in our case, we want to capture both `Tool` and `tool`, as well as `Tools` and `tools` so this approach makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bde51_row0_col1, #T_bde51_row0_col2, #T_bde51_row0_col3, #T_bde51_row0_col4, #T_bde51_row1_col1, #T_bde51_row1_col3, #T_bde51_row1_col4, #T_bde51_row2_col1, #T_bde51_row2_col3, #T_bde51_row3_col1, #T_bde51_row3_col3, #T_bde51_row4_col1, #T_bde51_row4_col3 {\n",
       "  color: red;\n",
       "}\n",
       "#T_bde51_row1_col2, #T_bde51_row2_col2, #T_bde51_row2_col4, #T_bde51_row3_col2, #T_bde51_row3_col4, #T_bde51_row4_col2, #T_bde51_row4_col4 {\n",
       "  color: blue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bde51\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bde51_level0_col0\" class=\"col_heading level0 col0\" >example_text</th>\n",
       "      <th id=\"T_bde51_level0_col1\" class=\"col_heading level0 col1\" >string_matching</th>\n",
       "      <th id=\"T_bde51_level0_col2\" class=\"col_heading level0 col2\" >tokenized_string_matching</th>\n",
       "      <th id=\"T_bde51_level0_col3\" class=\"col_heading level0 col3\" >lower_string_matching</th>\n",
       "      <th id=\"T_bde51_level0_col4\" class=\"col_heading level0 col4\" >tokenized_lower_string_matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bde51_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bde51_row0_col0\" class=\"data row0 col0\" >digital tools</td>\n",
       "      <td id=\"T_bde51_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_bde51_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "      <td id=\"T_bde51_row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "      <td id=\"T_bde51_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bde51_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bde51_row1_col0\" class=\"data row1 col0\" >Critical Tool Studies</td>\n",
       "      <td id=\"T_bde51_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_bde51_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_bde51_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "      <td id=\"T_bde51_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bde51_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bde51_row2_col0\" class=\"data row2 col0\" >Footstool</td>\n",
       "      <td id=\"T_bde51_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_bde51_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_bde51_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "      <td id=\"T_bde51_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bde51_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bde51_row3_col0\" class=\"data row3 col0\" >DH TOOLSETS</td>\n",
       "      <td id=\"T_bde51_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "      <td id=\"T_bde51_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_bde51_row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "      <td id=\"T_bde51_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bde51_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bde51_row4_col0\" class=\"data row4 col0\" >tooling up</td>\n",
       "      <td id=\"T_bde51_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "      <td id=\"T_bde51_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_bde51_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_bde51_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1775f36a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tool_data['lower_example_text'] = example_tool_data['example_text'].str.lower()\n",
    "example_tool_data['lower_string_matching'] = example_tool_data['lower_example_text'].str.count('tool|Tool|TOOL')\n",
    "example_tool_data['tokenized_lower_example_text'] = example_tool_data['lower_example_text'].apply(word_tokenize)\n",
    "example_tool_data['tokenized_string_matching'] = example_tool_data['tokenized_example_text'].apply(lambda x: sum(1 for token in x if token in ['tool', 'tools']))\n",
    "example_tool_data['tokenized_lower_string_matching'] = example_tool_data['tokenized_lower_example_text'].apply(lambda x: sum(1 for token in x if token in ['tool', 'tools']))\n",
    "example_tool_data[['example_text', 'string_matching', 'tokenized_string_matching', 'lower_string_matching', 'tokenized_lower_string_matching']].style.pipe(make_pretty, subset_columns=['string_matching', 'tokenized_string_matching', 'lower_string_matching', 'tokenized_lower_string_matching']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our tokenization, this time we are searching for both `tool` and `tools`, but we've also tried lowercasing our data. While we can see that the lowercased text is equally as permissive on string matching, but with tokenization we finally get our two instances of `tool` that we want to include. This is because we are now searching for `tool` and `tools` in our tokenized text, rather than just `tool`. We are not getting `Footstool` anymore, but we are also not getting `TOOLSETS` or `tooling`. In our article, we have decided to be a bit more restrictive and just focus on those most obvious instances of tool, but there are methods to get more of these examples if you want to be more inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 4: Lemmatization & Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main other methods for normalizing textual data are lemmatizing and stemming. Lemmatizing and stemming are both methods of reducing words to their root form. Lemmatizing is more sophisticated than stemming, but both are useful for reducing the number of unique words in your dataset. For example, `tools` and `tool` would both be reduced to `tool`. Whereas stemming is a bit more aggressive and would also lower case the word, so `Tools` would also be reduced to `tool`. We can do this with the `nltk.stem` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define functions for stemming and lemmatization\n",
    "def stem_text(tokens):\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "def lemmatize_text(tokens):\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digital tools</td>\n",
       "      <td>digit tool</td>\n",
       "      <td>digital tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Critical Tool Studies</td>\n",
       "      <td>critic tool studi</td>\n",
       "      <td>Critical Tool Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Footstool</td>\n",
       "      <td>footstool</td>\n",
       "      <td>Footstool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DH TOOLSETS</td>\n",
       "      <td>dh toolset</td>\n",
       "      <td>DH TOOLSETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tooling up</td>\n",
       "      <td>tool up</td>\n",
       "      <td>tooling up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            example_text       stemmed_text        lemmatized_text\n",
       "0          digital tools         digit tool           digital tool\n",
       "1  Critical Tool Studies  critic tool studi  Critical Tool Studies\n",
       "2              Footstool          footstool              Footstool\n",
       "3            DH TOOLSETS         dh toolset            DH TOOLSETS\n",
       "4             tooling up            tool up             tooling up"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the functions to the 'example_text' column\n",
    "example_tool_data['stemmed_text'] = example_tool_data['tokenized_example_text'].apply(stem_text)\n",
    "example_tool_data['lemmatized_text'] = example_tool_data['tokenized_example_text'].apply(lemmatize_text)\n",
    "example_tool_data[['example_text', 'stemmed_text', 'lemmatized_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that `stemming` took terms like `digital tools` and turned them into `digit tool`, or in the case of `Critical Tool Studies` it turned it into `critic tool studi`. However, we aren't seeing much changes with the lemmatizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digital tools</td>\n",
       "      <td>digit tool</td>\n",
       "      <td>digital tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Critical Tool Studies</td>\n",
       "      <td>critic tool studi</td>\n",
       "      <td>critical tool study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Footstool</td>\n",
       "      <td>footstool</td>\n",
       "      <td>footstool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DH TOOLSETS</td>\n",
       "      <td>dh toolset</td>\n",
       "      <td>dh toolsets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tooling up</td>\n",
       "      <td>tool up</td>\n",
       "      <td>tooling up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            example_text       stemmed_text      lemmatized_text\n",
       "0          digital tools         digit tool         digital tool\n",
       "1  Critical Tool Studies  critic tool studi  critical tool study\n",
       "2              Footstool          footstool            footstool\n",
       "3            DH TOOLSETS         dh toolset          dh toolsets\n",
       "4             tooling up            tool up           tooling up"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the functions to the 'example_text' column\n",
    "example_tool_data['stemmed_text'] = example_tool_data['tokenized_lower_example_text'].apply(stem_text)\n",
    "example_tool_data['lemmatized_text'] = example_tool_data['tokenized_lower_example_text'].apply(lemmatize_text)\n",
    "example_tool_data[['example_text', 'stemmed_text', 'lemmatized_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are running both methods on our `lowercased` and `tokenized` data. This time `lemmatizing` is turning `tools` into `tool`, and `studies` into `study`. Whereas `stemming` is not only transforming those terms, but also turning `toolsets` into `toolset` and `tooling` into `tool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2fa0_row0_col1, #T_f2fa0_row0_col2, #T_f2fa0_row0_col3, #T_f2fa0_row0_col4, #T_f2fa0_row1_col2, #T_f2fa0_row1_col3, #T_f2fa0_row1_col4, #T_f2fa0_row4_col4 {\n",
       "  color: red;\n",
       "}\n",
       "#T_f2fa0_row1_col1, #T_f2fa0_row2_col1, #T_f2fa0_row2_col2, #T_f2fa0_row2_col3, #T_f2fa0_row2_col4, #T_f2fa0_row3_col1, #T_f2fa0_row3_col2, #T_f2fa0_row3_col3, #T_f2fa0_row3_col4, #T_f2fa0_row4_col1, #T_f2fa0_row4_col2, #T_f2fa0_row4_col3 {\n",
       "  color: blue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2fa0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f2fa0_level0_col0\" class=\"col_heading level0 col0\" >example_text</th>\n",
       "      <th id=\"T_f2fa0_level0_col1\" class=\"col_heading level0 col1\" >tokenized_string_matching</th>\n",
       "      <th id=\"T_f2fa0_level0_col2\" class=\"col_heading level0 col2\" >tokenized_lower_string_matching</th>\n",
       "      <th id=\"T_f2fa0_level0_col3\" class=\"col_heading level0 col3\" >tokenized_lemmatized_string_matching</th>\n",
       "      <th id=\"T_f2fa0_level0_col4\" class=\"col_heading level0 col4\" >tokenized_stemmed_string_matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2fa0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f2fa0_row0_col0\" class=\"data row0 col0\" >digital tools</td>\n",
       "      <td id=\"T_f2fa0_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_f2fa0_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "      <td id=\"T_f2fa0_row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "      <td id=\"T_f2fa0_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2fa0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f2fa0_row1_col0\" class=\"data row1 col0\" >Critical Tool Studies</td>\n",
       "      <td id=\"T_f2fa0_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_f2fa0_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "      <td id=\"T_f2fa0_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "      <td id=\"T_f2fa0_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2fa0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f2fa0_row2_col0\" class=\"data row2 col0\" >Footstool</td>\n",
       "      <td id=\"T_f2fa0_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_f2fa0_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_f2fa0_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "      <td id=\"T_f2fa0_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2fa0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f2fa0_row3_col0\" class=\"data row3 col0\" >DH TOOLSETS</td>\n",
       "      <td id=\"T_f2fa0_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_f2fa0_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_f2fa0_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_f2fa0_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2fa0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f2fa0_row4_col0\" class=\"data row4 col0\" >tooling up</td>\n",
       "      <td id=\"T_f2fa0_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_f2fa0_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_f2fa0_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "      <td id=\"T_f2fa0_row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1774bdac0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tool_data['tokenized_lemmatized_text'] = example_tool_data['lemmatized_text'].apply(word_tokenize)\n",
    "example_tool_data['tokenized_lemmatized_string_matching'] = example_tool_data['tokenized_lemmatized_text'].apply(lambda x: sum(1 for token in x if token in ['tool', 'tools']))\n",
    "example_tool_data['tokenized_stemmed_text'] = example_tool_data['stemmed_text'].apply(word_tokenize)\n",
    "example_tool_data['tokenized_stemmed_string_matching'] = example_tool_data['tokenized_stemmed_text'].apply(lambda x: sum(1 for token in x if token in ['tool', 'tools']))\n",
    "example_tool_data[['example_text', 'tokenized_string_matching', 'tokenized_lower_string_matching', 'tokenized_lemmatized_string_matching', 'tokenized_stemmed_string_matching']].style.pipe(make_pretty, subset_columns=['tokenized_string_matching', 'tokenized_lower_string_matching','tokenized_lemmatized_string_matching', 'tokenized_stemmed_string_matching'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that if we rerun our tokenization and string matching code, `lemmatization` gets us similar results to simply lowercasing our data. Whereas `stemming` also gets the example of `tooling` that we were missing before. While we could use `stemming` in our article, we have decided to primarily use `lowercasing` and `tokenization`, along with `string matching` to balance both inclusivity and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 5: Our Article's Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final added transformation in our article is to not only count words, but to normalize those counts based on the length of their respective document. This helps us know if a term like `tool` is appearing more frequently because it is a longer document, or because it is actually more frequent. We can do this with the `str.len()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_000e3_row0_col1, #T_000e3_row0_col2, #T_000e3_row1_col1, #T_000e3_row1_col2, #T_000e3_row2_col1, #T_000e3_row2_col2, #T_000e3_row3_col1, #T_000e3_row3_col2, #T_000e3_row4_col1, #T_000e3_row4_col2 {\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_000e3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_000e3_level0_col0\" class=\"col_heading level0 col0\" >example_text</th>\n",
       "      <th id=\"T_000e3_level0_col1\" class=\"col_heading level0 col1\" >total_length</th>\n",
       "      <th id=\"T_000e3_level0_col2\" class=\"col_heading level0 col2\" >total_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_000e3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_000e3_row0_col0\" class=\"data row0 col0\" >digital tools</td>\n",
       "      <td id=\"T_000e3_row0_col1\" class=\"data row0 col1\" >13</td>\n",
       "      <td id=\"T_000e3_row0_col2\" class=\"data row0 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_000e3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_000e3_row1_col0\" class=\"data row1 col0\" >Critical Tool Studies</td>\n",
       "      <td id=\"T_000e3_row1_col1\" class=\"data row1 col1\" >21</td>\n",
       "      <td id=\"T_000e3_row1_col2\" class=\"data row1 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_000e3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_000e3_row2_col0\" class=\"data row2 col0\" >Footstool</td>\n",
       "      <td id=\"T_000e3_row2_col1\" class=\"data row2 col1\" >9</td>\n",
       "      <td id=\"T_000e3_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_000e3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_000e3_row3_col0\" class=\"data row3 col0\" >DH TOOLSETS</td>\n",
       "      <td id=\"T_000e3_row3_col1\" class=\"data row3 col1\" >11</td>\n",
       "      <td id=\"T_000e3_row3_col2\" class=\"data row3 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_000e3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_000e3_row4_col0\" class=\"data row4 col0\" >tooling up</td>\n",
       "      <td id=\"T_000e3_row4_col1\" class=\"data row4 col1\" >10</td>\n",
       "      <td id=\"T_000e3_row4_col2\" class=\"data row4 col2\" >2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1759dadc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tool_data['total_length'] = example_tool_data['example_text'].apply(len)\n",
    "example_tool_data['total_words'] = example_tool_data['tokenized_example_text'].apply(len)\n",
    "example_tool_data[['example_text', 'total_length', 'total_words']].style.pipe(make_pretty, subset_columns=['total_length', 'total_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that counting simply characters versus words gives us very different results. In our article, we have primarily counted words (or `tokens`) though again this approach is not perfect for every language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_633b7_row0_col1, #T_633b7_row0_col2, #T_633b7_row0_col3, #T_633b7_row0_col4, #T_633b7_row1_col1, #T_633b7_row1_col2, #T_633b7_row1_col3, #T_633b7_row1_col4, #T_633b7_row2_col2, #T_633b7_row3_col2, #T_633b7_row4_col2 {\n",
       "  color: red;\n",
       "}\n",
       "#T_633b7_row2_col1, #T_633b7_row2_col3, #T_633b7_row2_col4, #T_633b7_row3_col1, #T_633b7_row3_col3, #T_633b7_row3_col4, #T_633b7_row4_col1, #T_633b7_row4_col3, #T_633b7_row4_col4 {\n",
       "  color: blue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_633b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_633b7_level0_col0\" class=\"col_heading level0 col0\" >example_text</th>\n",
       "      <th id=\"T_633b7_level0_col1\" class=\"col_heading level0 col1\" >tokenized_lower_string_matching</th>\n",
       "      <th id=\"T_633b7_level0_col2\" class=\"col_heading level0 col2\" >total_words</th>\n",
       "      <th id=\"T_633b7_level0_col3\" class=\"col_heading level0 col3\" >scaled_tokenized_lower_string_matching</th>\n",
       "      <th id=\"T_633b7_level0_col4\" class=\"col_heading level0 col4\" >scaled_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_633b7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_633b7_row0_col0\" class=\"data row0 col0\" >digital tools</td>\n",
       "      <td id=\"T_633b7_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_633b7_row0_col2\" class=\"data row0 col2\" >2</td>\n",
       "      <td id=\"T_633b7_row0_col3\" class=\"data row0 col3\" >0.500000</td>\n",
       "      <td id=\"T_633b7_row0_col4\" class=\"data row0 col4\" >50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_633b7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_633b7_row1_col0\" class=\"data row1 col0\" >Critical Tool Studies</td>\n",
       "      <td id=\"T_633b7_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_633b7_row1_col2\" class=\"data row1 col2\" >3</td>\n",
       "      <td id=\"T_633b7_row1_col3\" class=\"data row1 col3\" >0.333333</td>\n",
       "      <td id=\"T_633b7_row1_col4\" class=\"data row1 col4\" >33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_633b7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_633b7_row2_col0\" class=\"data row2 col0\" >Footstool</td>\n",
       "      <td id=\"T_633b7_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_633b7_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "      <td id=\"T_633b7_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_633b7_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_633b7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_633b7_row3_col0\" class=\"data row3 col0\" >DH TOOLSETS</td>\n",
       "      <td id=\"T_633b7_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_633b7_row3_col2\" class=\"data row3 col2\" >2</td>\n",
       "      <td id=\"T_633b7_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "      <td id=\"T_633b7_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_633b7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_633b7_row4_col0\" class=\"data row4 col0\" >tooling up</td>\n",
       "      <td id=\"T_633b7_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_633b7_row4_col2\" class=\"data row4 col2\" >2</td>\n",
       "      <td id=\"T_633b7_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_633b7_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1775f3fd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tool_data['scaled_tokenized_lower_string_matching'] = example_tool_data['tokenized_lower_string_matching'] / example_tool_data['total_words']\n",
    "example_tool_data['scaled_percent'] = example_tool_data['scaled_tokenized_lower_string_matching'] * 100\n",
    "\n",
    "example_tool_data[['example_text', 'tokenized_lower_string_matching', 'total_words', 'scaled_tokenized_lower_string_matching', 'scaled_percent']].style.pipe(make_pretty, subset_columns=['tokenized_lower_string_matching', 'total_words', 'scaled_tokenized_lower_string_matching', 'scaled_percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our final results, which we have used in our article. We have decided to use `lowercasing` and `tokenization` to get our words, and then `string matching` to get our counts. We have also decided to normalize our counts by the length of the document and then finally we have turned those scaled results (which are very small) into percentages. This helps us compare across documents and see which terms are most frequent in each document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge-cases-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
